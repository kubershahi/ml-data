{"Title":{"0":"The AI Revolution: The Road to Superintelligence","1":"The AI Revolution: The Road to Superintelligence","2":"The AI Revolution: The Road to Superintelligence","3":"Do Things that Don't Scale","4":"Do Things that Don't Scale","5":"Do Things that Don't Scale","6":"Do Things that Don't Scale","7":"Do Things that Don't Scale","8":"Do Things that Don't Scale","9":"Do Things that Don't Scale","10":"Do Things that Don't Scale","11":"Do Things that Don't Scale","12":"Do Things that Don't Scale","13":"Do Things that Don't Scale"},"URL":{"0":"https:\/\/waitbutwhy.com\/2015\/01\/artificial-intelligence-revolution-1.html","1":"https:\/\/waitbutwhy.com\/2015\/01\/artificial-intelligence-revolution-1.html","2":"https:\/\/waitbutwhy.com\/2015\/01\/artificial-intelligence-revolution-1.html","3":"http:\/\/www.paulgraham.com\/ds.html","4":"http:\/\/www.paulgraham.com\/ds.html","5":"http:\/\/www.paulgraham.com\/ds.html","6":"http:\/\/www.paulgraham.com\/ds.html","7":"http:\/\/www.paulgraham.com\/ds.html","8":"http:\/\/www.paulgraham.com\/ds.html","9":"http:\/\/www.paulgraham.com\/ds.html","10":"http:\/\/www.paulgraham.com\/ds.html","11":"http:\/\/www.paulgraham.com\/ds.html","12":"http:\/\/www.paulgraham.com\/ds.html","13":"http:\/\/www.paulgraham.com\/ds.html"},"Section":{"0":"Introduction","1":"The Far Future\u2014Coming Soon","2":"The Road to Superintelligence","3":"Introduction","4":"Recruit","5":"Fragile","6":"Delight","7":"Experience","8":"Fire","9":"Meraki","10":"Consult","11":"Manual","12":"Big","13":"Vector"},"Original Text":{"0":"We are on the edge of change comparable to the rise of human life on Earth. \u2014 Vernor VingeWhat does it feel like to stand here?It seems like a pretty intense place to be standing\u2014but then you have to remember something about what it\u2019s like to stand on a time graph: you can\u2019t see what\u2019s to your right. So here\u2019s how it actually feels to stand there:Which probably feels pretty normal\u2026_______________","1":"Imagine taking a time machine back to 1750\u2014a time when the world was in a permanent power outage, long-distance communication meant either yelling loudly or firing a cannon in the air, and all transportation ran on hay. When you get there, you retrieve a dude, bring him to 2015, and then walk him around and watch him react to everything. It\u2019s impossible for us to understand what it would be like for him to see shiny capsules racing by on a highway, talk to people who had been on the other side of the ocean earlier in the day, watch sports that were being played 1,000 miles away, hear a musical performance that happened 50 years ago, and play with my magical wizard rectangle that he could use to capture a real-life image or record a living moment, generate a map with a paranormal moving blue dot that shows him where he is, look at someone\u2019s face and chat with them even though they\u2019re on the other side of the country, and worlds of other inconceivable sorcery. This is all before you show him the internet or explain things like the International Space Station, the Large Hadron Collider, nuclear weapons, or general relativity.This experience for him wouldn\u2019t be surprising or shocking or even mind-blowing\u2014those words aren\u2019t big enough. He might actually die.But here\u2019s the interesting thing\u2014if he then went back to 1750 and got jealous that we got to see his reaction and decided he wanted to try the same thing, he\u2019d take the time machine and go back the same distance, get someone from around the year 1500, bring him to 1750, and show him everything. And the 1500 guy would be shocked by a lot of things\u2014but he wouldn\u2019t die. It would be far less of an insane experience for him, because while 1500 and 1750 were very different, they were much less different than 1750 to 2015. The 1500 guy would learn some mind-bending shit about space and physics, he\u2019d be impressed with how committed Europe turned out to be with that new imperialism fad, and he\u2019d have to do some major revisions of his world map conception. But watching everyday life go by in 1750\u2014transportation, communication, etc.\u2014definitely wouldn\u2019t make him die.No, in order for the 1750 guy to have as much fun as we had with him, he\u2019d have to go much farther back\u2014maybe all the way back to about 12,000 BC, before the First Agricultural Revolution gave rise to the first cities and to the concept of civilization. If someone from a purely hunter-gatherer world\u2014from a time when humans were, more or less, just another animal species\u2014saw the vast human empires of 1750 with their towering churches, their ocean-crossing ships, their concept of being \u201cinside,\u201d and their enormous mountain of collective, accumulated human knowledge and discovery\u2014he\u2019d likely die.And then what if, after dying, he got jealous and wanted to do the same thing. If he went back 12,000 years to 24,000 BC and got a guy and brought him to 12,000 BC, he\u2019d show the guy everything and the guy would be like, \u201cOkay what\u2019s your point who cares.\u201d For the 12,000 BC guy to have the same fun, he\u2019d have to go back over 100,000 years and get someone he could show fire and language to for the first time.In order for someone to be transported into the future and die from the level of shock they\u2019d experience, they have to go enough years ahead that a \u201cdie level of progress,\u201d or a Die Progress Unit (DPU) has been achieved. So a DPU took over 100,000 years in hunter-gatherer times, but at the post-Agricultural Revolution rate, it only took about 12,000 years. The post-Industrial Revolution world has moved so quickly that a 1750 person only needs to go forward a couple hundred years for a DPU to have happened.This pattern\u2014human progress moving quicker and quicker as time goes on\u2014is what futurist Ray Kurzweil calls human history\u2019s Law of Accelerating Returns. This happens because more advanced societies have the ability to progress at a faster rate than less advanced societies\u2014because they\u2019re more advanced. 19th century humanity knew more and had better technology than 15th century humanity, so it\u2019s no surprise that humanity made far more advances in the 19th century than in the 15th century\u201415th century humanity was no match for 19th century humanity.11\u2190 open theseThis works on smaller scales too. The movie Back to the Future came out in 1985, and \u201cthe past\u201d took place in 1955. In the movie, when Michael J. Fox went back to 1955, he was caught off-guard by the newness of TVs, the prices of soda, the lack of love for shrill electric guitar, and the variation in slang. It was a different world, yes\u2014but if the movie were made today and the past took place in 1985, the movie could have had much more fun with much bigger differences. The character would be in a time before personal computers, internet, or cell phones\u2014today\u2019s Marty McFly, a teenager born in the late 90s, would be much more out of place in 1985 than the movie\u2019s Marty McFly was in 1955.This is for the same reason we just discussed\u2014the Law of Accelerating Returns. The average rate of advancement between 1985 and 2015 was higher than the rate between 1955 and 1985\u2014because the former was a more advanced world\u2014so much more change happened in the most recent 30 years than in the prior 30.So\u2014advances are getting bigger and bigger and happening more and more quickly. This suggests some pretty intense things about our future, right?Kurzweil suggests that the progress of the entire 20th century would have been achieved in only 20 years at the rate of advancement in the year 2000\u2014in other words, by 2000, the rate of progress was five times faster than the average rate of progress during the 20th century. He believes another 20th century\u2019s worth of progress happened between 2000 and 2014 and that another 20th century\u2019s worth of progress will happen by 2021, in only seven years. A couple decades later, he believes a 20th century\u2019s worth of progress will happen multiple times in the same year, and even later, in less than one month. All in all, because of the Law of Accelerating Returns, Kurzweil believes that the 21st century will achieve 1,000 times the progress of the 20th century.2If Kurzweil and others who agree with him are correct, then we may be as blown away by 2030 as our 1750 guy was by 2015\u2014i.e. the next DPU might only take a couple decades\u2014and the world in 2050 might be so vastly different than today\u2019s world that we would barely recognize it.This isn\u2019t science fiction. It\u2019s what many scientists smarter and more knowledgeable than you or I firmly believe\u2014and if you look at history, it\u2019s what we should logically predict.So then why, when you hear me say something like \u201cthe world 35 years from now might be totally unrecognizable,\u201d are you thinking, \u201cCool\u2026.but nahhhhhhh\u201d? Three reasons we\u2019re skeptical of outlandish forecasts of the future:1) When it comes to history, we think in straight lines. When we imagine the progress of the next 30 years, we look back to the progress of the previous 30 as an indicator of how much will likely happen. When we think about the extent to which the world will change in the 21st century, we just take the 20th century progress and add it to the year 2000. This was the same mistake our 1750 guy made when he got someone from 1500 and expected to blow his mind as much as his own was blown going the same distance ahead. It\u2019s most intuitive for us to think linearly, when we should be thinking exponentially. If someone is being more clever about it, they might predict the advances of the next 30 years not by looking at the previous 30 years, but by taking the current rate of progress and judging based on that. They\u2019d be more accurate, but still way off. In order to think about the future correctly, you need to imagine things moving at a much faster rate than they\u2019re moving now.2) The trajectory of very recent history often tells a distorted story. First, even a steep exponential curve seems linear when you only look at a tiny slice of it, the same way if you look at a little segment of a huge circle up close, it looks almost like a straight line. Second, exponential growth isn\u2019t totally smooth and uniform. Kurzweil explains that progress happens in \u201cS-curves\u201d:An S is created by the wave of progress when a new paradigm sweeps the world. The curve goes through three phases:1. Slow growth (the early phase of exponential growth)\n2. Rapid growth (the late, explosive phase of exponential growth)\n3. A leveling off as the particular paradigm matures3If you look only at very recent history, the part of the S-curve you\u2019re on at the moment can obscure your perception of how fast things are advancing. The chunk of time between 1995 and 2007 saw the explosion of the internet, the introduction of Microsoft, Google, and Facebook into the public consciousness, the birth of social networking, and the introduction of cell phones and then smart phones. That was Phase 2: the growth spurt part of the S. But 2008 to 2015 has been less groundbreaking, at least on the technological front. Someone thinking about the future today might examine the last few years to gauge the current rate of advancement, but that\u2019s missing the bigger picture. In fact, a new, huge Phase 2 growth spurt might be brewing right now.3) Our own experience makes us stubborn old men about the future. We base our ideas about the world on our personal experience, and that experience has ingrained the rate of growth of the recent past in our heads as \u201cthe way things happen.\u201d We\u2019re also limited by our imagination, which takes our experience and uses it to conjure future predictions\u2014but often, what we know simply doesn\u2019t give us the tools to think accurately about the future.2 When we hear a prediction about the future that contradicts our experience-based notion of how things work, our instinct is that the prediction must be naive. If I tell you, later in this post, that you may live to be 150, or 250, or not die at all, your instinct will be, \u201cThat\u2019s stupid\u2014if there\u2019s one thing I know from history, it\u2019s that everybody dies.\u201d And yes, no one in the past has not died. But no one flew airplanes before airplanes were invented either.So while nahhhhh might feel right as you read this post, it\u2019s probably actually wrong. The fact is, if we\u2019re being truly logical and expecting historical patterns to continue, we should conclude that much, much, much more should change in the coming decades than we intuitively expect. Logic also suggests that if the most advanced species on a planet keeps making larger and larger leaps forward at an ever-faster rate, at some point, they\u2019ll make a leap so great that it completely alters life as they know it and the perception they have of what it means to be a human\u2014kind of like how evolution kept making great leaps toward intelligence until finally it made such a large leap to the human being that it completely altered what it meant for any creature to live on planet Earth. And if you spend some time reading about what\u2019s going on today in science and technology, you start to see a lot of signs quietly hinting that life as we currently know it cannot withstand the leap that\u2019s coming next._______________","2":"What Is AI?If you\u2019re like me, you used to think Artificial Intelligence was a silly sci-fi concept, but lately you\u2019ve been hearing it mentioned by serious people, and you don\u2019t really quite get it.There are three reasons a lot of people are confused about the term AI:1) We associate AI with movies. Star Wars. Terminator. 2001: A Space Odyssey. Even the Jetsons. And those are fiction, as are the robot characters. So it makes AI sound a little fictional to us.2) AI is a broad topic. It ranges from your phone\u2019s calculator to self-driving cars to something in the future that might change the world dramatically. AI refers to all of these things, which is confusing.3) We use AI all the time in our daily lives, but we often don\u2019t realize it\u2019s AI. John McCarthy, who coined the term \u201cArtificial Intelligence\u201d in 1956, complained that \u201cas soon as it works, no one calls it AI anymore.\u201d4 Because of this phenomenon, AI often sounds like a mythical future prediction more than a reality. At the same time, it makes it sound like a pop concept from the past that never came to fruition. Ray Kurzweil says he hears people say that AI withered in the 1980s, which he compares to \u201cinsisting that the Internet died in the dot-com bust of the early 2000s.\u201d5So let\u2019s clear things up. First, stop thinking of robots. A robot is a container for AI, sometimes mimicking the human form, sometimes not\u2014but the AI itself is the computer inside the robot. AI is the brain, and the robot is its body\u2014if it even has a body. For example, the software and data behind Siri is AI, the woman\u2019s voice we hear is a personification of that AI, and there\u2019s no robot involved at all.Secondly, you\u2019ve probably heard the term \u201csingularity\u201d or \u201ctechnological singularity.\u201d This term has been used in math to describe an asymptote-like situation where normal rules no longer apply. It\u2019s been used in physics to describe a phenomenon like an infinitely small, dense black hole or the point we were all squished into right before the Big Bang. Again, situations where the usual rules don\u2019t apply. In 1993, Vernor Vinge wrote a famous essay in which he applied the term to the moment in the future when our technology\u2019s intelligence exceeds our own\u2014a moment for him when life as we know it will be forever changed and normal rules will no longer apply. Ray Kurzweil then muddled things a bit by defining the singularity as the time when the Law of Accelerating Returns has reached such an extreme pace that technological progress is happening at a seemingly-infinite pace, and after which we\u2019ll be living in a whole new world. I found that many of today\u2019s AI thinkers have stopped using the term, and it\u2019s confusing anyway, so I won\u2019t use it much here (even though we\u2019ll be focusing on that idea throughout).Finally, while there are many different types or forms of AI since AI is a broad concept, the critical categories we need to think about are based on an AI\u2019s caliber. There are three major AI caliber categories:AI Caliber 1) Artificial Narrow Intelligence (ANI): Sometimes referred to as Weak AI, Artificial Narrow Intelligence is AI that specializes in one area. There\u2019s AI that can beat the world chess champion in chess, but that\u2019s the only thing it does. Ask it to figure out a better way to store data on a hard drive, and it\u2019ll look at you blankly.AI Caliber 2) Artificial General Intelligence (AGI): Sometimes referred to as Strong AI, or Human-Level AI, Artificial General Intelligence refers to a computer that is as smart as a human across the board\u2014a machine that can perform any intellectual task that a human being can. Creating AGI is a much harder task than creating ANI, and we\u2019re yet to do it. Professor Linda Gottfredson describes intelligence as \u201ca very general mental capability that, among other things, involves the ability to reason, plan, solve problems, think abstractly, comprehend complex ideas, learn quickly, and learn from experience.\u201d AGI would be able to do all of those things as easily as you can.AI Caliber 3) Artificial Superintelligence (ASI): Oxford philosopher and leading AI thinker Nick Bostrom defines superintelligence as \u201can intellect that is much smarter than the best human brains in practically every field, including scientific creativity, general wisdom and social skills.\u201d Artificial Superintelligence ranges from a computer that\u2019s just a little smarter than a human to one that\u2019s trillions of times smarter\u2014across the board. ASI is the reason the topic of AI is such a spicy meatball and why the words \u201cimmortality\u201d and \u201cextinction\u201d will both appear in these posts multiple times.As of now, humans have conquered the lowest caliber of AI\u2014ANI\u2014in many ways, and it\u2019s everywhere. The AI Revolution is the road from ANI, through AGI, to ASI\u2014a road we may or may not survive but that, either way, will change everything.Let\u2019s take a close look at what the leading thinkers in the field believe this road looks like and why this revolution might happen way sooner than you might think:Where We Are Currently\u2014A World Running on ANIArtificial Narrow Intelligence is machine intelligence that equals or exceeds human intelligence or efficiency at a specific thing. A few examples:Cars are full of ANI systems, from the computer that figures out when the anti-lock brakes should kick in to the computer that tunes the parameters of the fuel injection systems. Google\u2019s self-driving car, which is being tested now, will contain robust ANI systems that allow it to perceive and react to the world around it.\nYour phone is a little ANI factory. When you navigate using your map app, receive tailored music recommendations from Pandora, check tomorrow\u2019s weather, talk to Siri, or dozens of other everyday activities, you\u2019re using ANI.\nYour email spam filter is a classic type of ANI\u2014it starts off loaded with intelligence about how to figure out what\u2019s spam and what\u2019s not, and then it learns and tailors its intelligence to you as it gets experience with your particular preferences. The Nest Thermostat does the same thing as it starts to figure out your typical routine and act accordingly.\nYou know the whole creepy thing that goes on when you search for a product on Amazon and then you see that as a \u201crecommended for you\u201d product on a different site, or when Facebook somehow knows who it makes sense for you to add as a friend? That\u2019s a network of ANI systems, working together to inform each other about who you are and what you like and then using that information to decide what to show you. Same goes for Amazon\u2019s \u201cPeople who bought this also bought\u2026\u201d thing\u2014that\u2019s an ANI system whose job it is to gather info from the behavior of millions of customers and synthesize that info to cleverly upsell you so you\u2019ll buy more things.\nGoogle Translate is another classic ANI system\u2014impressively good at one narrow task. Voice recognition is another, and there are a bunch of apps that use those two ANIs as a tag team, allowing you to speak a sentence in one language and have the phone spit out the same sentence in another.\nWhen your plane lands, it\u2019s not a human that decides which gate it should go to. Just like it\u2019s not a human that determined the price of your ticket.\nThe world\u2019s best Checkers, Chess, Scrabble, Backgammon, and Othello players are now all ANI systems.\nGoogle search is one large ANI brain with incredibly sophisticated methods for ranking pages and figuring out what to show you in particular. Same goes for Facebook\u2019s Newsfeed.\nAnd those are just in the consumer world. Sophisticated ANI systems are widely used in sectors and industries like military, manufacturing, and finance (algorithmic high-frequency AI traders account for more than half of equity shares traded on US markets6), and in expert systems like those that help doctors make diagnoses and, most famously, IBM\u2019s Watson, who contained enough facts and understood coy Trebek-speak well enough to soundly beat the most prolific Jeopardy champions.ANI systems as they are now aren\u2019t especially scary. At worst, a glitchy or badly-programmed ANI can cause an isolated catastrophe like knocking out a power grid, causing a harmful nuclear power plant malfunction, or triggering a financial markets disaster (like the 2010 Flash Crash when an ANI program reacted the wrong way to an unexpected situation and caused the stock market to briefly plummet, taking $1 trillion of market value with it, only part of which was recovered when the mistake was corrected).But while ANI doesn\u2019t have the capability to cause an existential threat, we should see this increasingly large and complex ecosystem of relatively-harmless ANI as a precursor of the world-altering hurricane that\u2019s on the way. Each new ANI innovation quietly adds another brick onto the road to AGI and ASI. Or as Aaron Saenz sees it, our world\u2019s ANI systems \u201care like the amino acids in the early Earth\u2019s primordial ooze\u201d\u2014the inanimate stuff of life that, one unexpected day, woke up.The Road From ANI to AGIWhy It\u2019s So HardNothing will make you appreciate human intelligence like learning about how unbelievably challenging it is to try to create a computer as smart as we are. Building skyscrapers, putting humans in space, figuring out the details of how the Big Bang went down\u2014all far easier than understanding our own brain or how to make something as cool as it. As of now, the human brain is the most complex object in the known universe.What\u2019s interesting is that the hard parts of trying to build AGI (a computer as smart as humans in general, not just at one narrow specialty) are not intuitively what you\u2019d think they are. Build a computer that can multiply two ten-digit numbers in a split second\u2014incredibly easy. Build one that can look at a dog and answer whether it\u2019s a dog or a cat\u2014spectacularly difficult. Make AI that can beat any human in chess? Done. Make one that can read a paragraph from a six-year-old\u2019s picture book and not just recognize the words but understand the meaning of them? Google is currently spending billions of dollars trying to do it. Hard things\u2014like calculus, financial market strategy, and language translation\u2014are mind-numbingly easy for a computer, while easy things\u2014like vision, motion, movement, and perception\u2014are insanely hard for it. Or, as computer scientist Donald Knuth puts it, \u201cAI has by now succeeded in doing essentially everything that requires \u2018thinking\u2019 but has failed to do most of what people and animals do \u2018without thinking.'\u201d7What you quickly realize when you think about this is that those things that seem easy to us are actually unbelievably complicated, and they only seem easy because those skills have been optimized in us (and most animals) by hundreds of millions of years of animal evolution. When you reach your hand up toward an object, the muscles, tendons, and bones in your shoulder, elbow, and wrist instantly perform a long series of physics operations, in conjunction with your eyes, to allow you to move your hand in a straight line through three dimensions. It seems effortless to you because you have perfected software in your brain for doing it. Same idea goes for why it\u2019s not that malware is dumb for not being able to figure out the slanty word recognition test when you sign up for a new account on a site\u2014it\u2019s that your brain is super impressive for being able to.On the other hand, multiplying big numbers or playing chess are new activities for biological creatures and we haven\u2019t had any time to evolve a proficiency at them, so a computer doesn\u2019t need to work too hard to beat us. Think about it\u2014which would you rather do, build a program that could multiply big numbers or one that could understand the essence of a B well enough that you could show it a B in any one of thousands of unpredictable fonts or handwriting and it could instantly know it was a B?One fun example\u2014when you look at this, you and a computer both can figure out that it\u2019s a rectangle with two distinct shades, alternating:Tied so far. But if you pick up the black and reveal the whole image\u2026\u2026you have no problem giving a full description of the various opaque and translucent cylinders, slats, and 3-D corners, but the computer would fail miserably. It would describe what it sees\u2014a variety of two-dimensional shapes in several different shades\u2014which is actually what\u2019s there. Your brain is doing a ton of fancy shit to interpret the implied depth, shade-mixing, and room lighting the picture is trying to portray.8 And looking at the picture below, a computer sees a two-dimensional white, black, and gray collage, while you easily see what it really is\u2014a photo of an entirely-black, 3-D rock:Credit: Matthew LloydAnd everything we just mentioned is still only taking in stagnant information and processing it. To be human-level intelligent, a computer would have to understand things like the difference between subtle facial expressions, the distinction between being pleased, relieved, content, satisfied, and glad, and why Braveheart was great but The Patriot was terrible.Daunting.So how do we get there?First Key to Creating AGI: Increasing Computational PowerOne thing that definitely needs to happen for AGI to be a possibility is an increase in the power of computer hardware. If an AI system is going to be as intelligent as the brain, it\u2019ll need to equal the brain\u2019s raw computing capacity.One way to express this capacity is in the total calculations per second (cps) the brain could manage, and you could come to this number by figuring out the maximum cps of each structure in the brain and then adding them all together.Ray Kurzweil came up with a shortcut by taking someone\u2019s professional estimate for the cps of one structure and that structure\u2019s weight compared to that of the whole brain and then multiplying proportionally to get an estimate for the total. Sounds a little iffy, but he did this a bunch of times with various professional estimates of different regions, and the total always arrived in the same ballpark\u2014around 1016, or 10 quadrillion cps.Currently, the world\u2019s fastest supercomputer, China\u2019s Tianhe-2, has actually beaten that number, clocking in at about 34 quadrillion cps. But Tianhe-2 is also a dick, taking up 720 square meters of space, using 24 megawatts of power (the brain runs on just 20 watts), and costing $390 million to build. Not especially applicable to wide usage, or even most commercial or industrial usage yet.Kurzweil suggests that we think about the state of computers by looking at how many cps you can buy for $1,000. When that number reaches human-level\u201410 quadrillion cps\u2014then that\u2019ll mean AGI could become a very real part of life.Moore\u2019s Law is a historically-reliable rule that the world\u2019s maximum computing power doubles approximately every two years, meaning computer hardware advancement, like general human advancement through history, grows exponentially. Looking at how this relates to Kurzweil\u2019s cps\/$1,000 metric, we\u2019re currently at about 10 trillion cps\/$1,000, right on pace with this graph\u2019s predicted trajectory:9So the world\u2019s $1,000 computers are now beating the mouse brain and they\u2019re at about a thousandth of human level. This doesn\u2019t sound like much until you remember that we were at about a trillionth of human level in 1985, a billionth in 1995, and a millionth in 2005. Being at a thousandth in 2015 puts us right on pace to get to an affordable computer by 2025 that rivals the power of the brain.So on the hardware side, the raw power needed for AGI is technically available now, in China, and we\u2019ll be ready for affordable, widespread AGI-caliber hardware within 10 years. But raw computational power alone doesn\u2019t make a computer generally intelligent\u2014the next question is, how do we bring human-level intelligence to all that power?Second Key to Creating AGI: Making It SmartThis is the icky part. The truth is, no one really knows how to make it smart\u2014we\u2019re still debating how to make a computer human-level intelligent and capable of knowing what a dog and a weird-written B and a mediocre movie is. But there are a bunch of far-fetched strategies out there and at some point, one of them will work. Here are the three most common strategies I came across:1) Plagiarize the brain.This is like scientists toiling over how that kid who sits next to them in class is so smart and keeps doing so well on the tests, and even though they keep studying diligently, they can\u2019t do nearly as well as that kid, and then they finally decide \u201ck fuck it I\u2019m just gonna copy that kid\u2019s answers.\u201d It makes sense\u2014we\u2019re stumped trying to build a super-complex computer, and there happens to be a perfect prototype for one in each of our heads.The science world is working hard on reverse engineering the brain to figure out how evolution made such a rad thing\u2014optimistic estimates say we can do this by 2030. Once we do that, we\u2019ll know all the secrets of how the brain runs so powerfully and efficiently and we can draw inspiration from it and steal its innovations. One example of computer architecture that mimics the brain is the artificial neural network. It starts out as a network of transistor \u201cneurons,\u201d connected to each other with inputs and outputs, and it knows nothing\u2014like an infant brain. The way it \u201clearns\u201d is it tries to do a task, say handwriting recognition, and at first, its neural firings and subsequent guesses at deciphering each letter will be completely random. But when it\u2019s told it got something right, the transistor connections in the firing pathways that happened to create that answer are strengthened; when it\u2019s told it was wrong, those pathways\u2019 connections are weakened. After a lot of this trial and feedback, the network has, by itself, formed smart neural pathways and the machine has become optimized for the task. The brain learns a bit like this but in a more sophisticated way, and as we continue to study the brain, we\u2019re discovering ingenious new ways to take advantage of neural circuitry.More extreme plagiarism involves a strategy called \u201cwhole brain emulation,\u201d where the goal is to slice a real brain into thin layers, scan each one, use software to assemble an accurate reconstructed 3-D model, and then implement the model on a powerful computer. We\u2019d then have a computer officially capable of everything the brain is capable of\u2014it would just need to learn and gather information. If engineers get really good, they\u2019d be able to emulate a real brain with such exact accuracy that the brain\u2019s full personality and memory would be intact once the brain architecture has been uploaded to a computer. If the brain belonged to Jim right before he passed away, the computer would now wake up as Jim (?), which would be a robust human-level AGI, and we could now work on turning Jim into an unimaginably smart ASI, which he\u2019d probably be really excited about.How far are we from achieving whole brain emulation? Well so far, we\u2019ve not yet just recently been able to emulate a 1mm-long flatworm brain, which consists of just 302 total neurons. The human brain contains 100 billion. If that makes it seem like a hopeless project, remember the power of exponential progress\u2014now that we\u2019ve conquered the tiny worm brain, an ant might happen before too long, followed by a mouse, and suddenly this will seem much more plausible.2) Try to make evolution do what it did before but for us this time.So if we decide the smart kid\u2019s test is too hard to copy, we can try to copy the way he studies for the tests instead.Here\u2019s something we know. Building a computer as powerful as the brain is possible\u2014our own brain\u2019s evolution is proof. And if the brain is just too complex for us to emulate, we could try to emulate evolution instead. The fact is, even if we can emulate a brain, that might be like trying to build an airplane by copying a bird\u2019s wing-flapping motions\u2014often, machines are best designed using a fresh, machine-oriented approach, not by mimicking biology exactly.So how can we simulate evolution to build AGI? The method, called \u201cgenetic algorithms,\u201d would work something like this: there would be a performance-and-evaluation process that would happen again and again (the same way biological creatures \u201cperform\u201d by living life and are \u201cevaluated\u201d by whether they manage to reproduce or not). A group of computers would try to do tasks, and the most successful ones would be bred with each other by having half of each of their programming merged together into a new computer. The less successful ones would be eliminated. Over many, many iterations, this natural selection process would produce better and better computers. The challenge would be creating an automated evaluation and breeding cycle so this evolution process could run on its own.The downside of copying evolution is that evolution likes to take a billion years to do things and we want to do this in a few decades.But we have a lot of advantages over evolution. First, evolution has no foresight and works randomly\u2014it produces more unhelpful mutations than helpful ones, but we would control the process so it would only be driven by beneficial glitches and targeted tweaks. Secondly, evolution doesn\u2019t aim for anything, including intelligence\u2014sometimes an environment might even select against higher intelligence (since it uses a lot of energy). We, on the other hand, could specifically direct this evolutionary process toward increasing intelligence. Third, to select for intelligence, evolution has to innovate in a bunch of other ways to facilitate intelligence\u2014like revamping the ways cells produce energy\u2014when we can remove those extra burdens and use things like electricity. It\u2019s no doubt we\u2019d be much, much faster than evolution\u2014but it\u2019s still not clear whether we\u2019ll be able to improve upon evolution enough to make this a viable strategy.3) Make this whole thing the computer\u2019s problem, not ours.This is when scientists get desperate and try to program the test to take itself. But it might be the most promising method we have.The idea is that we\u2019d build a computer whose two major skills would be doing research on AI and coding changes into itself\u2014allowing it to not only learn but to improve its own architecture. We\u2019d teach computers to be computer scientists so they could bootstrap their own development. And that would be their main job\u2014figuring out how to make themselves smarter. More on this later.All of This Could Happen SoonRapid advancements in hardware and innovative experimentation with software are happening simultaneously, and AGI could creep up on us quickly and unexpectedly for two main reasons:1) Exponential growth is intense and what seems like a snail\u2019s pace of advancement can quickly race upwards\u2014this GIF illustrates this concept nicely:Source2) When it comes to software, progress can seem slow, but then one epiphany can instantly change the rate of advancement (kind of like the way science, during the time humans thought the universe was geocentric, was having difficulty calculating how the universe worked, but then the discovery that it was heliocentric suddenly made everything much easier). Or, when it comes to something like a computer that improves itself, we might seem far away but actually be just one tweak of the system away from having it become 1,000 times more effective and zooming upward to human-level intelligence.The Road From AGI to ASIAt some point, we\u2019ll have achieved AGI\u2014computers with human-level general intelligence. Just a bunch of people and computers living together in equality.Oh actually not at all.The thing is, AGI with an identical level of intelligence and computational capacity as a human would still have significant advantages over humans. Like:Hardware:Speed. The brain\u2019s neurons max out at around 200 Hz, while today\u2019s microprocessors (which are much slower than they will be when we reach AGI) run at 2 GHz, or 10 million times faster than our neurons. And the brain\u2019s internal communications, which can move at about 120 m\/s, are horribly outmatched by a computer\u2019s ability to communicate optically at the speed of light.\nSize and storage. The brain is locked into its size by the shape of our skulls, and it couldn\u2019t get much bigger anyway, or the 120 m\/s internal communications would take too long to get from one brain structure to another. Computers can expand to any physical size, allowing far more hardware to be put to work, a much larger working memory (RAM), and a longterm memory (hard drive storage) that has both far greater capacity and precision than our own.\nReliability and durability. It\u2019s not only the memories of a computer that would be more precise. Computer transistors are more accurate than biological neurons, and they\u2019re less likely to deteriorate (and can be repaired or replaced if they do). Human brains also get fatigued easily, while computers can run nonstop, at peak performance, 24\/7.Software:Editability, upgradability, and a wider breadth of possibility. Unlike the human brain, computer software can receive updates and fixes and can be easily experimented on. The upgrades could also span to areas where human brains are weak. Human vision software is superbly advanced, while its complex engineering capability is pretty low-grade. Computers could match the human on vision software but could also become equally optimized in engineering and any other area.\nCollective capability. Humans crush all other species at building a vast collective intelligence. Beginning with the development of language and the forming of large, dense communities, advancing through the inventions of writing and printing, and now intensified through tools like the internet, humanity\u2019s collective intelligence is one of the major reasons we\u2019ve been able to get so far ahead of all other species. And computers will be way better at it than we are. A worldwide network of AI running a particular program could regularly sync with itself so that anything any one computer learned would be instantly uploaded to all other computers. The group could also take on one goal as a unit, because there wouldn\u2019t necessarily be dissenting opinions and motivations and self-interest, like we have within the human population.10AI, which will likely get to AGI by being programmed to self-improve, wouldn\u2019t see \u201chuman-level intelligence\u201d as some important milestone\u2014it\u2019s only a relevant marker from our point of view\u2014and wouldn\u2019t have any reason to \u201cstop\u201d at our level. And given the advantages over us that even human intelligence-equivalent AGI would have, it\u2019s pretty obvious that it would only hit human intelligence for a brief instant before racing onwards to the realm of superior-to-human intelligence.This may shock the shit out of us when it happens. The reason is that from our perspective, A) while the intelligence of different kinds of animals varies, the main characteristic we\u2019re aware of about any animal\u2019s intelligence is that it\u2019s far lower than ours, and B) we view the smartest humans as WAY smarter than the dumbest humans. Kind of like this:So as AI zooms upward in intelligence toward us, we\u2019ll see it as simply becoming smarter, for an animal. Then, when it hits the lowest capacity of humanity\u2014Nick Bostrom uses the term \u201cthe village idiot\u201d\u2014we\u2019ll be like, \u201cOh wow, it\u2019s like a dumb human. Cute!\u201d The only thing is, in the grand spectrum of intelligence, all humans, from the village idiot to Einstein, are within a very small range\u2014so just after hitting village idiot level and being declared to be AGI, it\u2019ll suddenly be smarter than Einstein and we won\u2019t know what hit us:And what happens\u2026after that?An Intelligence ExplosionI hope you enjoyed normal time, because this is when this topic gets unnormal and scary, and it\u2019s gonna stay that way from here forward. I want to pause here to remind you that every single thing I\u2019m going to say is real\u2014real science and real forecasts of the future from a large array of the most respected thinkers and scientists. Just keep remembering that.Anyway, as I said above, most of our current models for getting to AGI involve the AI getting there by self-improvement. And once it gets to AGI, even systems that formed and grew through methods that didn\u2019t involve self-improvement would now be smart enough to begin self-improving if they wanted to.3And here\u2019s where we get to an intense concept: recursive self-improvement. It works like this\u2014An AI system at a certain level\u2014let\u2019s say human village idiot\u2014is programmed with the goal of improving its own intelligence. Once it does, it\u2019s smarter\u2014maybe at this point it\u2019s at Einstein\u2019s level\u2014so now when it works to improve its intelligence, with an Einstein-level intellect, it has an easier time and it can make bigger leaps. These leaps make it much smarter than any human, allowing it to make even bigger leaps. As the leaps grow larger and happen more rapidly, the AGI soars upwards in intelligence and soon reaches the superintelligent level of an ASI system. This is called an Intelligence Explosion,11 and it\u2019s the ultimate example of The Law of Accelerating Returns.There is some debate about how soon AI will reach human-level general intelligence. The median year on a survey of hundreds of scientists about when they believed we\u2019d be more likely than not to have reached AGI was 204012\u2014that\u2019s only 25 years from now, which doesn\u2019t sound that huge until you consider that many of the thinkers in this field think it\u2019s likely that the progression from AGI to ASI happens very quickly. Like\u2014this could happen:It takes decades for the first AI system to reach low-level general intelligence, but it finally happens. A computer is able to understand the world around it as well as a human four-year-old. Suddenly, within an hour of hitting that milestone, the system pumps out the grand theory of physics that unifies general relativity and quantum mechanics, something no human has been able to definitively do. 90 minutes after that, the AI has become an ASI, 170,000 times more intelligent than a human.Superintelligence of that magnitude is not something we can remotely grasp, any more than a bumblebee can wrap its head around Keynesian Economics. In our world, smart means a 130 IQ and stupid means an 85 IQ\u2014we don\u2019t have a word for an IQ of 12,952.What we do know is that humans\u2019 utter dominance on this Earth suggests a clear rule: with intelligence comes power. Which means an ASI, when we create it, will be the most powerful being in the history of life on Earth, and all living things, including humans, will be entirely at its whim\u2014and this might happen in the next few decades.If our meager brains were able to invent wifi, then something 100 or 1,000 or 1 billion times smarter than we are should have no problem controlling the positioning of each and every atom in the world in any way it likes, at any time\u2014everything we consider magic, every power we imagine a supreme God to have will be as mundane an activity for the ASI as flipping on a light switch is for us. Creating the technology to reverse human aging, curing disease and hunger and even mortality, reprogramming the weather to protect the future of life on Earth\u2014all suddenly possible. Also possible is the immediate end of all life on Earth. As far as we\u2019re concerned, if an ASI comes to being, there is now an omnipotent God on Earth\u2014and the all-important question for us is:Will it be a nice God?","3":"One of the most common types of advice we give at Y Combinator is\nto do things that don't scale.  A lot of would-be founders believe\nthat startups either take off or don't.  You build something, make\nit available, and if you've made a better mousetrap, people beat a\npath to your door as promised.  Or they don't, in which case the\nmarket must not exist.Actually startups take off because the founders make them take off.\nThere may be a handful that just grew by themselves, but usually\nit takes some sort of push to get them going.  A good metaphor would\nbe the cranks that car engines had before they got electric starters.\nOnce the engine was going, it would keep going, but there was a\nseparate and laborious process to get it going.","4":"The most common unscalable thing founders have to do at the start\nis to recruit users manually.  Nearly all startups have to.  You\ncan't wait for users to come to you.  You have to go out and get\nthem.Stripe is one of the most successful startups we've funded, and the\nproblem they solved was an urgent one.   If anyone could have sat\nback and waited for users, it was Stripe.  But in fact they're\nfamous within YC for aggressive early user acquisition.Startups building things for other startups have a big pool of\npotential users in the other companies we've funded, and none took\nbetter advantage of it than Stripe.  At YC we use the term \"Collison\ninstallation\" for the technique they invented.  More diffident\nfounders ask \"Will you try our beta?\" and if the answer is yes,\nthey say \"Great, we'll send you a link.\"  But the Collison brothers\nweren't going to wait. When anyone agreed to try Stripe they'd say\n\"Right then, give me your laptop\" and set them up on the spot.There are two reasons founders resist going out and recruiting users\nindividually.  One is a combination of shyness and laziness.  They'd\nrather sit at home writing code than go out and talk to a bunch of\nstrangers and probably be rejected by most of them.  But for a\nstartup to succeed, at least one founder (usually the CEO) will\nhave to spend a lot of time on sales and marketing.The other reason founders ignore this path is that the absolute\nnumbers seem so small at first.  This can't be how the big, famous\nstartups got started, they think. The mistake they make is to\nunderestimate the power of compound growth.  We encourage every\nstartup to measure their progress by weeklyYou'll be doing different things when you're acquiring users a\nthousand at a time, and growth has to slow down eventually.  But\nif the market exists you can usually start by recruiting users\nmanually and then gradually switch to less manual methods.Airbnb is a classic example of this technique.  Marketplaces are\nso hard to get rolling that you should expect to take heroic measures\nat first. In Airbnb's case, these consisted of going door to door\nin New York, recruiting new users and helping existing ones improve\ntheir listings.  When I remember the Airbnbs during YC, I picture\nthem with rolly bags, because when they showed up for tuesday dinners\nthey'd always just flown back from somewhere.","5":"Airbnb now seems like an unstoppable juggernaut, but early on it\nwas so fragile that about 30 days of going out and engaging in\nperson with users made the difference between success and failure.That initial fragility was not a unique feature of Airbnb.  Almost\nall startups are fragile initially.  And that's one of the biggest\nthings inexperienced founders and investors (and reporters and\nknow-it-alls on forums) get wrong about them.  They unconsciously\njudge larval startups by the standards of established ones.  They're\nlike someone looking at a newborn baby and concluding \"there's no\nway this tiny creature could ever accomplish anything.\"It's harmless if reporters and know-it-alls dismiss your startup.\nThey always get things wrong.   It's even ok if investors dismiss\nyour startup; they'll change their minds when they see growth.  The\nbig danger is that you'll dismiss your startup yourself.  I've seen\nit happen.  I often have to encourage founders who don't see the\nfull potential of what they're building.  Even Bill Gates made that\nmistake.  He returned to Harvard for the fall semester after starting\nMicrosoft.  He didn't stay long, but he wouldn't have returned at\nall if he'd realized Microsoft was going to be even a fraction of\nthe size it turned out to be.The question to ask about an early stage startup is not \"is this\ncompany taking over the world?\"  but \"how big could this company\nget if the founders did the right things?\"  And the right things\noften seem both laborious and inconsequential at the time. Microsoft\ncan't have seemed very impressive when it was just a couple guys\nin Albuquerque writing Basic interpreters for a market of a few\nthousand hobbyists (as they were then called), but in retrospect\nthat was the optimal path to dominating microcomputer software.\nAnd I know Brian Chesky and Joe Gebbia didn't feel like they were\nen route to the big time as they were taking \"professional\" photos\nof their first hosts' apartments.  They were just trying to survive.\nBut in retrospect that too was the optimal path to dominating a big\nmarket.How do you find users to recruit manually?  If you build something\nto solve","6":"You should take extraordinary measures not just to acquire users,\nbut also to make them happy.  For as long as they could (which\nturned out to be surprisingly long), Wufoo sent each new user a\nhand-written thank you note.  Your first users should feel that\nsigning up with you was one of the best choices they ever made.\nAnd you in turn should be racking your brains to think of new ways\nto delight them.Why do we have to teach startups this?  Why is it counterintuitive\nfor founders?  Three reasons, I think.One is that a lot of startup founders are trained as engineers,\nand customer service is not part of the training of engineers.\nYou're supposed to build things that are robust and elegant, not\nbe slavishly attentive to individual users like some kind of\nsalesperson.  Ironically, part of the reason engineering is\ntraditionally averse to handholding is that its traditions date\nfrom a time when engineers were less powerful \u2014 when they were\nonly in charge of their narrow domain of building things, rather\nthan running the whole show.  You can be ornery when you're Scotty,\nbut not when you're Kirk.Another reason founders don't focus enough on individual customers\nis that they worry it won't scale.  But when founders of larval\nstartups worry about this, I point out that in their current state\nthey have nothing to lose.  Maybe if they go out of their way to\nmake existing users super happy, they'll one day have too many to\ndo so much for.  That would be a great problem to have.  See if you\ncan make it happen.  And incidentally, when it does, you'll find\nthat delighting customers scales better than you expected.  Partly\nbecause you can usually find ways to make anything scale more than\nyou would have predicted, and partly because delighting customers\nwill by then have permeated your culture.I have never once seen a startup lured down a blind alley by trying\ntoo hard to make their initial users happy.But perhaps the biggest thing preventing founders from realizing\nhow attentive they could be to their users is that they've never\nexperienced such attention themselves.  Their standards for customer\nservice have been set by the companies they've been customers of,\nwhich are mostly big ones.  Tim Cook doesn't send you a hand-written\nnote after you buy a laptop.  He can't.  But you can.  That's one\nadvantage of being small: you can provide a level of service no big\ncompany can.Once you realize that existing conventions are not the upper bound\non user experience, it's interesting in a very pleasant way to think\nabout how far you could go to delight your users.","7":"I was trying to think of a phrase to convey how extreme your attention\nto users should be, and I realized Steve Jobs had already done it:\ninsanely great.  Steve wasn't just using \"insanely\" as a synonym\nfor \"very.\"  He meant it more literally \u2014 that one should focus\non quality of execution to a degree that in everyday life would be\nconsidered pathological.All the most successful startups we've funded have, and that probably\ndoesn't surprise would-be founders.  What novice founders don't get\nis what insanely great translates to in a larval startup.  When\nSteve Jobs started using that phrase, Apple was already an established\ncompany.  He meant the Mac (and its documentation and even\npackaging \u2014 such is the nature of obsession) should be insanely\nwell designed and manufactured.  That's not hard for engineers to\ngrasp.  It's just a more extreme version of designing a robust and\nelegant product.What founders have a hard time grasping (and Steve himself might\nhave had a hard time grasping) is what insanely great morphs into\nas you roll the time slider back to the first couple months of a\nstartup's life.  It's not the product that should be insanely great,\nbut the experience of being your user.  The product is just one\ncomponent of that.  For a big company it's necessarily the dominant\none.  But you can and should give users an insanely great experience\nwith an early, incomplete, buggy product, if you make up the\ndifference with attentiveness.Can, perhaps, but should?  Yes.  Over-engaging with early users is\nnot just a permissible technique for getting growth rolling.  For\nmost successful startups it's a necessary part of the feedback loop\nthat makes the product good.  Making a better mousetrap is not an\natomic operation.  Even if you start the way most successful startups\nhave, by building something you yourself need, the first thing you\nbuild is never quite right.  And except in domains with big penalties\nfor making mistakes, it's often better not to aim for perfection\ninitially.  In software, especially, it usually works best to get\nsomething in front of users as soon as it has a quantum of utility,\nand then see what they do with it.  Perfectionism is often an excuse\nfor procrastination, and in any case your initial model of users\nis always inaccurate, even if you're one of them.The feedback you get from engaging directly with your earliest users\nwill be the best you ever get.  When you're so big you have to\nresort to focus groups, you'll wish you could go over to your users'\nhomes and offices and watch them use your stuff like you did when\nthere were only a handful of them.","8":"Sometimes the right unscalable trick is to focus on a deliberately\nnarrow market.  It's like keeping a fire contained at first to get\nit really hot before adding more logs.That's what Facebook did.  At first it was just for Harvard students.\nIn that form it only had a potential market of a few thousand people,\nbut because they felt it was really for them, a critical mass of\nthem signed up.  After Facebook stopped being for Harvard students,\nit remained for students at specific colleges for quite a while.\nWhen I interviewed Mark Zuckerberg at Startup School, he said that\nwhile it was a lot of work creating course lists for each school,\ndoing that made students feel the site was their natural home.Any startup that could be described as a marketplace usually has\nto start in a subset of the market, but this can work for other\nstartups as well.  It's always worth asking if there's a subset of\nthe market in which you can get a critical mass of users quickly.Most startups that use the contained fire strategy do it unconsciously.\nThey build something for themselves and their friends, who happen\nto be the early adopters, and only realize later that they could\noffer it to a broader market.  The strategy works just as well if\nyou do it unconsciously.  The biggest danger of not being consciously\naware of this pattern is for those who naively discard part of it.\nE.g. if you don't build something for yourself and your friends,\nor even if you do, but you come from the corporate world and your\nfriends are not early adopters, you'll no longer have a perfect\ninitial market handed to you on a platter.Among companies, the best early adopters are usually other startups.\nThey're more open to new things both by nature and because, having\njust been started, they haven't made all their choices yet.  Plus\nwhen they succeed they grow fast, and you with them.  It was one\nof many unforeseen advantages of the YC model (and specifically of\nmaking YC big) that B2B startups now have an instant market of\nhundreds of other startups ready at hand.","9":"ForHardware startups face an obstacle that software startups don't.\nThe minimum order for a factory production run is usually several\nhundred thousand dollars.  Which can put you in a catch-22: without\na product you can't generate the growth you need to raise the money\nto manufacture your product.  Back when hardware startups had to\nrely on investors for money, you had to be pretty convincing to\novercome this.  The arrival of crowdfunding (or more precisely,\npreorders) has helped a lot.  But even so I'd advise startups to\npull a Meraki initially if they can.  That's what Pebble did.  The\nPebblesLike paying excessive attention to early customers, fabricating\nthings yourself turns out to be valuable for hardware startups.\nYou can tweak the design faster when you're the factory, and you\nlearn things you'd never have known otherwise.  Eric Migicovsky of\nPebble said one of the things he learned was \"how valuable it was to\nsource good screws.\"   Who knew?","10":"Sometimes we advise founders of B2B startups to take over-engagement\nto an extreme, and to pick a single user and act as if they were\nconsultants building something just for that one user.   The initial\nuser serves as the form for your mold; keep tweaking till you fit\ntheir needs perfectly, and you'll usually find you've made something\nother users want too.  Even if there aren't many of them, there are\nprobably adjacent territories that have more.  As long as you can\nfind just one user who really needs something and can act on that\nneed, you've got a toehold in making something people want, and\nthat's as much as any startup needs initially.Consulting is the canonical example of work that doesn't scale.\nBut (like other ways of bestowing one's favors liberally) it's safe\nto do it so long as you're not being paid to.  That's where companies\ncross the line.  So long as you're a product company that's merely\nbeing extra attentive to a customer, they're very grateful even if\nyou don't solve all their problems.  But when they start paying you\nspecifically for that attentiveness \u2014 when they start paying\nyou by the hour \u2014 they expect you to do everything.Another consulting-like technique for recruiting initially lukewarm\nusers is to use your software yourselves on their behalf.  We\ndid that at Viaweb.  When we approached merchants asking if they\nwanted to use our software to make online stores, some said no, but\nthey'd let us make one for them.  Since we would do anything to get\nusers, we did.  We felt pretty lame at the time.  Instead of\norganizing big strategic e-commerce partnerships, we were trying\nto sell luggage and pens and men's shirts.  But in retrospect it\nwas exactly the right thing to do, because it taught us how it would\nfeel to merchants to use our software.  Sometimes the feedback loop\nwas near instantaneous: in the middle of building some merchant's\nsite I'd find I needed a feature we didn't have, so I'd spend a\ncouple hours implementing it and then resume building the site.","11":"There's a more extreme variant where you don't just use your software,\nbut are your software.  When you only have a small number of users,\nyou can sometimes get away with doing by hand things that you plan\nto automate later.  This lets you launch faster, and when you do\nfinally automate yourself out of the loop, you'll know exactly what\nto build because you'll have muscle memory from doing it yourself.When manual components look to the user like software, this technique\nstarts to have aspects of a practical joke.  For example, the way\nStripe delivered \"instant\" merchant accounts to its first users was\nthat the founders manually signed them up for traditional merchant\naccounts behind the scenes.Some startups could be entirely manual at first. If you can find\nsomeone with a problem that needs solving and you can solve it\nmanually, go ahead and do that for as long as you can, and then\ngradually automate the bottlenecks.  It would be a little frightening\nto be solving users' problems in a way that wasn't yet automatic,\nbut less frightening than the far more common case of having something\nautomatic that doesn't yet solve anyone's problems.","12":"I should mention one sort of initial tactic that usually doesn't\nwork: the Big Launch.  I occasionally meet founders who seem to\nbelieve startups are projectiles rather than powered aircraft, and\nthat they'll make it big if and only if they're launched with\nsufficient initial velocity.  They want to launch simultaneously\nin 8 different publications, with embargoes.  And on a tuesday, of\ncourse, since they read somewhere that's the optimum day to launch\nsomething.It's easy to see how little launches matter.  Think of some successful\nstartups.  How many of their launches do you remember?\nAll you need from a launch is some initial core of users.  How well\nyou're doing a few months later will depend more on how happy you\nmade those users than how many there were of them.So why do founders think launches matter?  A combination of solipsism\nand laziness.  They think what they're building is so great that\neveryone who hears about it will immediately sign up.  Plus it would\nbe so much less work if you could get users merely by broadcasting\nyour existence, rather than recruiting them one at a time.  But\neven if what you're building really is great, getting users will\nalways be a gradual process \u2014 partly because great things\nare usually also novel, but mainly because users have other things\nto think about.Partnerships too usually don't work.  They don't work for startups\nin general, but they especially don't work as a way to get growth\nstarted.  It's a common mistake among inexperienced founders to\nbelieve that a partnership with a big company will be their big\nbreak.  Six months later they're all saying the same thing: that\nwas way more work than we expected, and we ended up getting practically\nnothing out of it.It's not enough just to do something extraordinary initially.  You\nhave to make an extraordinary","13":"The need to do something unscalably laborious to get started is so\nnearly universal that it might be a good idea to stop thinking of\nstartup ideas as scalars.  Instead we should try thinking of them\nas pairs of what you're going to build, plus the unscalable thing(s)\nyou're going to do initially to get the company going.It could be interesting to start viewing startup ideas this way,\nbecause now that there are two components you can try to be imaginative\nabout the second as well as the first.  But in most cases the second\ncomponent will be what it usually is \u2014 recruit users manually\nand give them an overwhelmingly good experience \u2014 and the main\nbenefit of treating startups as vectors will be to remind founders\nthey need to work hard in two dimensions.In the best case, both components of the vector contribute to your\ncompany's DNA: the unscalable things you have to do to get started\nare not merely a necessary evil, but change the company permanently\nfor the better.  If you have to be aggressive about user acquisition\nwhen you're small, you'll probably still be aggressive when you're\nbig.  If you have to manufacture your own hardware, or use your\nsoftware on users's behalf, you'll learn things you couldn't have\nlearned otherwise.  And most importantly, if you have to work hard\nto delight users when you only have a handful of them, you'll keep\ndoing it when you have a lot."},"Summary":{"0":" We are on the edge of change comparable to the rise of human life on Earth . It seems like a pretty intense place to be standing, but then you have to remember something about what it's like to stand on a time graph: you can\u2019t see what's to your right .","1":" A time machine would take a man from around the year 1500, bring him to 1750, and show him everything . It would be far less of an insane experience for him, because while 1500 and 1750 were very different, they were much less different than 1750 to 2015 . In order for the 1750 guy to have","2":"There are three reasons a lot of people are confused about the term AI . John McCarthy, who coined the term \u2018Artificial Intelligence\u2019 in 1956, complained that \u201cas soon as it works, no one calls it AI anymore\u2019s AI.\u2019","3":" A lot of would-be founders believe that startups either take off or don't . A good metaphor would be the cranks that car engines had before they got electric starters . Once the engine was going, it would keep going, but there was aseparate and laborious process to get it going .","4":"Stripe is one of the most successful startups we've funded, and the problem they solved was an urgent one . But in fact they're famous within YC for aggressive early user acquisition . There are two reasons founders resist going out and recruiting users individually . The mistake they make is tounderestimate the power of compound","5":" Airbnb now seems like an unstoppable juggernaut, but early on it was so fragile that about 30 days of going out and engaging in users made the difference between success and failure . It's harmless if reporters and know-it-alls dismiss your startup; they'll change their minds when they see growth .","6":" Wufoo sent each new user a hand-written thank you note after you bought a laptop . Why do we have to teach startups this? Why is it counterintuitive for founders? One reason is that a lot of startup founders are trained as engineers, and customer service is not part of the training of engineers .","7":" Steve Jobs used \"insanely\" as a synonym for \"very\" when he started using that phrase . He meant it more literally \u2014 that one should focus on quality of execution to a degree that in everyday life would be pathological . For most successful startups it's a necessary part of the feedback loop that makes the product good.","8":" The strategy works just as well if you don't do it unconsciously. Most startups that use the contained fire strategy do it subconsciously . The biggest danger of not being consciously aware of this pattern is for those who naively discard part of it . B2B startups now have an instant market of hundreds of other startups ready at hand","9":" For hardware startups face an obstacle that software startups don't have to raise money to manufacture their product . The arrival of crowdfunding has helped a lot, but even so I'd advise startups to pull a Meraki initially if they can . The Pebbles like paying excessive attention to early customers, fabricating things yourself turns out to be valuable","10":"Consulting is the canonical example of work that doesn't scale, but it's safe to do it so long as you're not being paid to . The initialuser serves as the form for your mold; keep tweaking till you fit your needs perfectly . Another consulting-like technique for recruiting initially lukewarmusers is to","11":"When you only have a small number of users, you can sometimes get away with doing by hand things that you plan to automate later . This lets you launch faster, and when you do it yourself, you'll know exactly what to build because you'll have muscle memory from doing it yourself .","12":" The Big Launch is an initial tactic that usually doesn't work. It's a common mistake among inexperienced founders to believe that a partnership with a big company will be their big break . It's not enough just to do something extraordinary initially, says the author . But getting users will always be a gradual process, he says .","13":" The need to do something unscalably laborious to get started is so universal that it might be a good idea to stop thinking of start-up ideas as scalars . Instead we should try thinking of them pairs of what you're going to build, plus the unscalable thing(s) you're Going to do"}}